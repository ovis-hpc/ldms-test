#!/usr/bin/env python3

# Synopsis: Test configuration for 2 levels of aggregators with 8 samplers
# First level has 3 aggregators, 2nd level has 1 aggregator

import argparse
import json
import logging
import os
import TADA
import tempfile
import time
import sys
import atexit

from distutils.spawn import find_executable
from LDMS_Test import LDMSDCluster, LDMSDContainer, process_args, \
                      add_common_args, jprint, parse_ldms_ls, cs_rm


if __name__ != "__main__":
    raise RuntimeError("This should not be imported as a module.")

class Debug(object):
    pass
D = Debug()

logging.basicConfig(format = "%(asctime)s %(name)s %(levelname)s %(message)s",
                    level = logging.INFO)

log = logging.getLogger(__name__)

exec(open(os.getenv("PYTHONSTARTUP", "/dev/null")).read())

#### default values #### ---------------------------------------------
sbin_ldmsd = find_executable("ldmsd")
if sbin_ldmsd:
    default_prefix, a, b = sbin_ldmsd.rsplit('/', 2)
else:
    default_prefix = "/opt/ovis"

#### argument parsing #### -------------------------------------------
DESC = "Test for ldmsd configuration with maestro_ctrl"
ap = argparse.ArgumentParser(description = "Configuration tests for agg with 2 samplers")
add_common_args(ap)
args = ap.parse_args()
process_args(args)

#### config variables #### -------------------------------------------
USER = args.user
PREFIX = args.prefix
COMMIT_ID = args.commit_id
SRC = args.src
CLUSTERNAME = args.clustername
DB = args.data_root
NUM_COMPUTE = 8
STORE_ROOT = "/store" # path inside container (aggs)
CFG_PREFIX = "headnode"
LDMS_PORT = 10000
STORE_PATH = "/db/containers"
LDMS_CFG_FILE = "/db/ldms_cfg.yaml"
ETCD_FILE = "/db/etcd.yaml"


# Edit etcd to run
ETCD_YAML = """cluster: %(cfg_prefix)s
members:
  - host: localhost
    port: 2379

""" % { "cfg_prefix" : CFG_PREFIX }
MAESTRO_CFG = f"""\
daemons:
  - names : &sampler-daemons "samp-[1-8]"
    hosts : &sampler-hosts "node-[1-8]"
    endpoints :
      - names : &sampler-endpoints "samp-[1-8]-ep"
        ports : "[{LDMS_PORT}]"
        xprt : sock
        maestro_comm : True
        auth :
          name : none
          plugin : none

  - names : &l1-daemons "agg-[1-3]"
    hosts : &l1-hosts "agg-[1-3]"
    endpoints :
      - names: &l1-endpoints "agg-[1-3]-ep"
        ports : "[{LDMS_PORT}]"
        xprt : sock
        maestro_comm : True
        auth :
          name : none
          plugin : none

  - names : &l2-daemons "agg-[4]"
    hosts : &l2-hosts "headnode"
    endpoints :
      - names: &l2-endpoints "agg-[4]-ep"
        ports: "{LDMS_PORT}"
        xprt : sock
        maestro_comm : True
        auth :
          name : none
          plugin : none

aggregators:
  - daemons   : *l1-daemons
    peers     :
      - daemons   : *sampler-daemons
        endpoints : *sampler-endpoints
        reconnect : 1s
        type      : active
        updaters  : &updtr
          - mode     : pull
            interval : "1.0s"
            offset   : "0ms"
            sets     :
              - regex : .*
                field : inst
  - daemons : *l2-daemons
    peers:
      - daemons : *l1-daemons
        endpoints : *l1-endpoints
        reconnect : 1s
        type      : active
        updaters  : *updtr

samplers:
  - daemons : *sampler-daemons
    plugins : &sampler-plugins
      - name        : meminfo # Variables can be specific to plugin
        interval    : "1s" # Used when starting the sampler plugin
        offset      : "0s"
        config : &simple_samp_config
            component_id : "${{COMPID}}"
            perm : "0777"

stores:
  - name      : sos-meminfo
    daemons   : *l2-daemons
    container : ldms_data
    schema    : meminfo
    flush     : 10s
    plugin :
      name   : store_sos
      config :
        path : {STORE_PATH}
"""

#### spec #### -------------------------------------------------------
spec = {
    "name" : CLUSTERNAME,
    "description" : "{}'s test_agg cluster".format(USER),
    "type" : "NA",
    "templates" : { # generic template can apply to any object by "!extends"
        "ldms-daemon" : {
            "name" : "ldmsd",
            "type" : "ldmsd",
            "listen" : [
                { "port" : LDMS_PORT, "xprt" : "sock" }
            ],
            "config" : [
                "env COMPID=%component_id%",
            ],
        },
        "ldms-node" : { # generic ldms node
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd"
                },
                {
                    "name" : "ldmsd",
                    "type" : "ldmsd",
                    "!extends" : "ldms-daemon",
                }
            ]
        },
    }, # templates
    "nodes" : [
        {
            "hostname" : "node-{}".format(i),
            "component_id" : i,
            "!extends" : "ldms-node",
        } for i in range(1, NUM_COMPUTE+1)
    ] + [

        {
            "hostname" : "agg-{}".format(j),
            "component_id" : 0,
            "!extends" : "ldms-node",
        } for j in [1, 2, 3]
    ] + [
        {
            "hostname" : "headnode",
            "component_id" : 0,
            "daemons" : [
                {
                    "name" : "etcd",
                    "type" : "etcd"
                },
                {
                    "name" : "sshd",
                    "type" : "sshd"
                },
                {
                    "name" : "agg-4",
                    "!extends" : "ldms-daemon",
                }
            ]
        },
    ], # nodes

    "cap_add": [ "SYS_PTRACE", "SYS_ADMIN" ],
    "image": "ovis-centos-build",
    "ovis_prefix": PREFIX,
    "env" : {
        "FOO": "BAR",
         },
    "mounts": [
        f"{DB}:/db:rw",
        f"{os.path.realpath(sys.path[0])}:/tada-src:ro",
    ] + args.mount +
    ( ["{0}:{0}:ro".format(SRC)] if SRC else [] ),
}

#### test definition ####

test = TADA.Test(test_suite = "LDMSD",
                 test_type = "FVT",
                 test_name = "maestro_cfg_test",
                 test_desc = DESC,
                 test_user = args.user,
                 commit_id = COMMIT_ID,
                 tada_addr = args.tada_addr)

test.add_assertion(1, "load maestro etcd cluster")
test.add_assertion(2, "config ldmsd cluster with maestro")
test.add_assertion(3, "verify sampler daemons")
test.add_assertion(4, "verify L1 aggregator daemons")
test.add_assertion(5, "verify L2 aggregator daemon")
test.add_assertion(6, "verify data storage")

#### Helper Functions ####

#### start ####
cluster = None
test.start()

@atexit.register
def at_exit():
    rc = test.finish()
    def rm_f(path):
        try:
            os.remove(path)
        except:
            pass
    rm_f(DB+"/etcd.yaml")
    rm_f(DB+"/ldms_cfg.yaml")
    if cluster is not None:
        cluster.remove()
    os._exit(rc)

# Check maestro + maestro_ctrl
_m = [ args.prefix+"/bin/maestro", args.prefix+"/sbin/maestro" ]
_m_ctrl = [ args.prefix+"/bin/maestro_ctrl", args.prefix+"/sbin/maestro_ctrl" ]

_m_exists = (os.path.exists(_m[0]) or os.path.exists(_m[1])) and \
            (os.path.exists(_m_ctrl[0]) or os.path.exists(_m_ctrl[1]))
if not _m_exists:
    log.info("maestro and/or maestro_ctrl not found, skipping tests")
    sys.exit()

if not os.path.isdir(DB+"/containers"):
    os.mkdir(DB+"/containers")

### Write test config files ###
etcd_cfg = open(DB+"/etcd.yaml", "w")
ldms_cfg = open(DB+"/ldms_cfg.yaml", "w")
etcd_cfg.write(ETCD_YAML)
ldms_cfg.write(MAESTRO_CFG)
print("---Wait for config to write to file---")
time.sleep(10)
etcd_cfg.close()
ldms_cfg.close()

log.info("-- Get or create cluster --")
cluster = LDMSDCluster.get(spec['name'], create = True, spec = spec)

headnode = cluster.get_container("headnode")
node1 = cluster.get_container("node-1")
node2 = cluster.get_container("node-2")
node3 = cluster.get_container("node-3")
node4 = cluster.get_container("node-4")
node5 = cluster.get_container("node-5")
node6 = cluster.get_container("node-6")
node7 = cluster.get_container("node-7")
node8 = cluster.get_container("node-8")
agg1 = cluster.get_container("agg-1")
agg2 = cluster.get_container("agg-2")
agg3 = cluster.get_container("agg-3")

headnode.exec_run("mkdir -p {}".format(STORE_PATH))

log.info("-- Start daemons --")
try:
    cluster.start_daemons()
    cluster.make_known_hosts()

    log.info("... make sure ldmsd's are up")
    time.sleep(5)

    # Test 1 test.add_assertion(1, "load maestro etcd cluster")
    cmd = "maestro_ctrl --cluster "+ETCD_FILE+ \
            " --ldms_config " +LDMS_CFG_FILE+ \
            " --prefix "+CFG_PREFIX + " 2>/dev/null"
    cmd = "bash -c '{}'".format(cmd)
    rc, out = headnode.exec_run(cmd)
    expected_out = "LDMS aggregator configuration saved to etcd cluster.\n"
    if expected_out == out:
        test.assert_test(1, True, "etcd cluster loaded successfully")
    else:
        test.assert_test(1, False, "Unexpected output: {}".format(out))
except Exception as e:
    raise
    a, b, c = sys.exc_info()
    print(str(e)+str(c.tb_lineno))
    if cluster:
        cluster.remove()
    sys.exit(-1)

# Test 2 start maestro and configure ldmsd's
cmd = "maestro --cluster "+ETCD_FILE+" --prefix "+CFG_PREFIX + " 2>/dev/null"
cmd = "bash -c '{}'".format(cmd)
maestro = headnode.exec_interact(cmd)
out = maestro.read(idle_timeout=20)
expected_out = """\
Rebalance cluster...\r
Adding sampler plugins to sampler samp-1\r
Adding sampler plugins to sampler samp-2\r
Adding sampler plugins to sampler samp-3\r
Adding sampler plugins to sampler samp-4\r
Adding sampler plugins to sampler samp-5\r
Adding sampler plugins to sampler samp-6\r
Adding sampler plugins to sampler samp-7\r
Adding sampler plugins to sampler samp-8\r
Starting.. meminfo on samp-1\r
Starting.. meminfo on samp-2\r
Starting.. meminfo on samp-3\r
Starting.. meminfo on samp-4\r
Starting.. meminfo on samp-5\r
Starting.. meminfo on samp-6\r
Starting.. meminfo on samp-7\r
Starting.. meminfo on samp-8\r
Adding 8 producers to agg agg-1\r
Adding 8 producers to agg agg-2\r
Adding 8 producers to agg agg-3\r
Adding 3 producers to agg agg-4\r
Starting agg agg-1 3 producers\r
Starting agg agg-2 3 producers\r
Starting agg agg-3 2 producers\r
Starting agg agg-4 3 producers\r
Finished load balancing.\r
"""

if expected_out == out:
    test.assert_test(2, True, "Maestro ldmsd configuration successful")
else:
    test.assert_test(2, False, "Unexpected output: {}".format(out))

def ldms_ls(host, _from = headnode):
    cmd = f"/tada-src/python/ldms_ls.py -h {host} -p {LDMS_PORT} -x sock -l"
    rc, out = headnode.exec_run(cmd)
    if rc:
        raise RuntimeError(f"ldms_ls error {rc}, out: {out}")
    obj = json.loads(out)
    return obj

#test.add_assertion(3, "verify sampler daemons")
for i in range(1, 9):
    obj = ldms_ls(f"node-{i}")
    # expecting "samp-{i}/meminfo"
    keys = [ k for k in obj.keys() ]
    expected_keys = [ f"samp-{i}/meminfo" ]
    if keys != expected_keys:
        test.assert_test(3, False, f"Expecting [ {expected_keys} ], but got [ {keys} ]")
        break
    s = obj[keys[0]]
    # verify component_id and sniff-check MemTotal value
    comp_id = s["metrics"]["component_id"]
    memtotal = s["metrics"]["MemTotal"]
    if comp_id != i:
        test.assert_test(3, False, f"Expecting component_id {i}, but got {comp_id}")
        break
    if memtotal <= 0:
        test.assert_test(3, False, f"Bad MemTotal value ({memtotal})")
        break
else: # loop completed w/o break
    test.assert_test(3, True, "OK")

#test.add_assertion(4, "verify L1 aggregator daemons")
for i in range(1, 4):
    obj = ldms_ls(f"agg-{i}")
    # expecting "samp-{i}/meminfo"
    keys = [ k for k in obj.keys() ]
    keys.sort()
    a = 1 + (i-1)*3
    b = a + 3 if i < 3 else a + 2
    expected_keys = [ f"samp-{j}/meminfo" for j in range(a, b) ]
    if keys != expected_keys:
        test.assert_test(4, False, f"Expecting [ {expected_keys} ], but got [ {keys} ]")
        break
    for k, s in obj.items():
        # verify component_id and sniff-check MemTotal value
        comp_id  = s["metrics"]["component_id"]
        memtotal = s["metrics"]["MemTotal"]
        expected_comp_id = int(k.replace("/meminfo", "").replace("samp-", ""))
        if comp_id != expected_comp_id:
            test.assert_test(4, False, f"Expecting component_id {expected_comp_id}, but got {comp_id}")
            break
        if memtotal <= 0:
            test.assert_test(4, False, f"Bad MemTotal value ({memtotal})")
            break
    else:
        continue
    break
else:
    test.assert_test(4, True, "OK")

#test.add_assertion(5, "verify L2 aggregator daemon")
while True: # will break
    obj = ldms_ls(f"headnode")
    # expecting "samp-{i}/meminfo"
    keys = [ k for k in obj.keys() ]
    keys.sort()
    expected_keys = [ f"samp-{j}/meminfo" for j in range(1, 9) ]
    if keys != expected_keys:
        test.assert_test(5, False, f"Expecting [ {expected_keys} ], but got [ {keys} ]")
        break
    for k, s in obj.items():
        # verify component_id and sniff-check MemTotal value
        comp_id  = s["metrics"]["component_id"]
        memtotal = s["metrics"]["MemTotal"]
        expected_comp_id = int(k.replace("/meminfo", "").replace("samp-", ""))
        if comp_id != expected_comp_id:
            test.assert_test(5, False, f"Expecting component_id {expected_comp_id}, but got {comp_id}")
            break
        if memtotal <= 0:
            test.assert_test(5, False, f"Bad MemTotal value ({memtotal})")
            break
    else:
        test.assert_test(5, True, "OK")
    break

#test.add_assertion(6, "verify data storage")
while True: # will break
    cmd = "sos_cmd -C /db/containers/ldms_data -q -S meminfo -X job_time_comp -f json"
    rc, out = headnode.exec_run(cmd)
    if rc:
        test.assert_test(6, False, f"sos_cmd error, output: {out}")
        break
    json_out = json.loads(out)
    objs = json_out['data']
    comp_stat = dict()
    bad = 0
    for o in objs:
        comp_id = o["component_id"]
        count = comp_stat.get(comp_id, 0)
        comp_stat[comp_id] = count + 1
        # sniff check MemTotal
        memtotal = o["MemTotal"]
        if memtotal <= 0:
            test.assert_test(6, False, f"Bad value MemTotal {MemTotal}, comp_id {comp_id}")
            bad = 1
            break
    if bad:
        break
    expected_keys = [ i for i in range(1, 9) ]
    keys = [ k for k in comp_stat ]
    keys.sort()
    if keys != expected_keys:
        test.assert_test(6, False, f"Expecting component_ids {expected_keys},"
                                   f" but got {keys}")
        break
    bad = 0
    for k, v in comp_stat.items():
        if v <= 0:
            test.assert_test(6, False, f"Bad component stat: comp_id {k}, count {v}")
            bad = 1
            break
    if bad:
        break
    test.assert_test(6, True, "OK")
    break

# EOF ; see at_exit()
