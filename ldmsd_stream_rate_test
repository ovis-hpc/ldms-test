#!/usr/bin/python3
#
# README
# ------
#
# Test rate limit.
#
#       pysub@agg-1
#            ^
#            |
#       ldmsd@agg-1 ## limit rx rate here
#            ^
#            |
#       ldmsd@samp
#            ^
#            |
#       pypub@samp

import os
import io
import re
import pwd
import pdb
import sys
import json
import time
import atexit
import argparse
import TADA
import logging

from distutils.spawn import find_executable
from LDMS_Test import LDMSDCluster, LDMSDContainer, process_args, \
                      add_common_args, jprint, parse_ldms_ls, PyPty, \
                      StreamData

if __name__ != "__main__":
    raise RuntimeError("This should not be impoarted as a module.")

class Debug(object):
    pass
D = Debug()

logging.basicConfig(format = "%(asctime)s %(name)s %(levelname)s %(message)s",
                    level = logging.INFO)

log = logging.getLogger(__name__)

exec(open(os.getenv("PYTHONSTARTUP", "/dev/null")).read())

#### default values #### ---------------------------------------------
sbin_ldmsd = find_executable("ldmsd")
if sbin_ldmsd:
    default_prefix, a, b = sbin_ldmsd.rsplit('/', 2)
else:
    default_prefix = "/opt/ovis"

#### argument parsing #### -------------------------------------------
ap = argparse.ArgumentParser(description = "Test ldms_stream features with ldmsd")
add_common_args(ap)
args = ap.parse_args()
process_args(args)

#### config variables #### ------------------------------
USER = args.user
PREFIX = args.prefix
COMMIT_ID = args.commit_id
SRC = args.src
CLUSTERNAME = args.clustername
DB = args.data_root
LDMSD_PORT = 10000

#### spec #### -------------------------------------------------------

def munge_key(i):
    return '0'*1024

common_plugin_config = [
        "component_id=%component_id%",
        "instance=%hostname%/%plugin%",
        "producer=%hostname%",
    ]
base_daemons = [
        {
            "name" : "munged",
            "type" : "munged",
            "key"  : munge_key(0),
        },
    ]
spec = {
    "name" : CLUSTERNAME,
    "description" : "{}'s ldms_stream test cluster".format(USER),
    "type" : "NA",
    "templates" : { # generic template can apply to any object by "!extends"
        "ldmsd_daemon" : {
            "name" : "ldmsd",
            "type" : "ldmsd",
            "listen" : [
                { "port" : LDMSD_PORT, "xprt" : "sock" },
            ],
        },
        "samp_daemon" : {
            "!extends" : "ldmsd_daemon",
            "samplers" : [
                {
                    "plugin" : "meminfo",
                    "interval" : 1000000,
                    "offset" : 0,
                    "config" : common_plugin_config,
                    "start" : True,
                },
            ],
        },
        "compute_node" : {
            "daemons" : base_daemons + [
                { "!extends" : "ldmsd_daemon" },
            ],
        },
    }, # templates
    "nodes" : [
        {
            "hostname" : f"agg-1",
            "daemons" : base_daemons + [
                {
                    "!extends" : "ldmsd_daemon",
                    "offset" : 200000,
                    "prdcrs" : [
                        {
                            "name" : f"{h}",
                            "host" : f"{h}",
                            "port" : LDMSD_PORT,
                            "xprt" : "sock",
                            "type" : "active",
                            "interval" : 1000000,
                            "rx_rate" : 64, # 64 bytes / sec
                        } for h in [ "samp" ]
                    ],
                    "config" : [ # additional config applied after prdcrs
                        "load name=stream_dump",
                        "config name=stream_dump op=subscribe stream=.* path=/db/%hostname%.txt",
                        "prdcr_subscribe regex=samp stream=new.*",
                        "prdcr_subscribe regex=samp stream=rate.* rx_rate=32",
                        "prdcr_start_regex regex=.*",
                        "updtr_add name=all interval=1000000 offset=%offset%",
                        "updtr_prdcr_add name=all regex=.*",
                        "updtr_start name=all",
                    ],
                },
            ],
        },
        {
            "hostname" : f"samp",
            "!extends" : "compute_node",
        },
    ], # nodes

    "cap_add": [ "SYS_PTRACE", "SYS_ADMIN" ],
    "image": args.image,
    "ovis_prefix": PREFIX,
    "env" : {
        "FOO": "BAR" ,
        "LDMS_STREAM_STATS_LEVEL" : "2",
    },
    "mounts": [
        "{}:/db:rw".format(DB),
        "{0}:{1}:ro".format(os.path.realpath(sys.path[0]), "/tada-src"),
    ] + args.mount +
    ( ["{0}:{0}:ro".format(SRC)] if SRC else [] ),
}

#### helper functions ####

def EXPECT(val, expected):
    if val != expected:
        raise RuntimeError("\n  EXPECTING: {}\n  GOT: {}".format(expected, val))

#### test definition ####

test = TADA.Test(test_suite = "LDMSD",
                 test_type = "FVT",
                 test_name = "ldmsd_stream_rate_test",
                 test_desc = "Test ldms_stream rate (on rails) with ldmsd",
                 test_user = args.user,
                 commit_id = COMMIT_ID,
                 tada_addr = args.tada_addr)

test.add_assertion( 1, "Sampler cannot publish all data (prdcr rate limit)")
test.add_assertion( 2, "After the wait, the sampler can publish")
test.add_assertion( 3, "Sampler cannot publish all data (stream rate limit)")
test.add_assertion( 4, "After the wait, the sampler can publish")

cluster = None
test.start()

@atexit.register
def at_exit():
    rc = test.finish()
    if cluster is not None:
        cluster.remove()
    os._exit(rc)

log.info("-- Get or create the cluster --")
cluster = LDMSDCluster.get(spec["name"], create = True, spec = spec)

agg1 = cluster.get_container("agg-1")
samp = cluster.get_container("samp")
nodes = [ agg1, samp ]

log.info("-- Start daemons --")
cluster.start_daemons()

log.info("... wait a bit to make sure ldmsd's are up")
time.sleep(2)

pypub = PyPty(samp, "/tada-src/python/pypubsub.py")
pysub = PyPty(agg1, "/tada-src/python/pypubsub.py")

# subscirbe all streams from agg-1
pysub.cmd("r.stream_subscribe('.*', True)")

# publish stream
pypub.cmd("[ r.stream_publish('new_string', 16*f'{I:x}') for I in range(0, 16) ]")
time.sleep(2)

pypub.cmd("r.stream_publish('new_string', 28*'x')")
time.sleep(2)

pypub.cmd("[ r.stream_publish('rate', 16*f'{I:x}') for I in range(0, 16) ]")
time.sleep(2)

pypub.cmd("r.stream_publish('rate', 28*'x')")
time.sleep(2)

agg1_dump = open(f"{DB}/agg-1.txt").read()

def dump2array(dump_text):
    rec_list = dump_text.split('\x01')[1:] # skip the first empty record
    return [ r.split(': ', 1)[1] for r in rec_list ]

x_28 = 28 * 'x' + '\n' # the data after the wait
agg1_recs = dump2array(agg1_dump)

idx = agg1_recs.index(x_28)
recs1 = agg1_recs[:(idx+1)]
recs2 = agg1_recs[(idx+1):]

set_full = set([ 16*f'{I:x}' + '\n' for I in range(0, 16) ])
set_1 = set(recs1) - set([ x_28 ])
set_2 = set(recs2) - set([ x_28 ])

# test.add_assertion( 1, "Sampler cannot publish all data (rate limit)")
while True: # will break
    if not set_1:
        test.assert_test(1, False, "empty stream data")
        break
    if not set_1 < set_full:
        test.assert_test(1, False, f"Got extra data: {set_1}")
        break
    tot_len = sum( len(o) for o in set_1 )
    if tot_len > 2*64 : # allow 2 times as the publish may cross 'the second' boundary
        test.assert_test(1, False, f"stream data received {tot_len} is greater than the prdcr rx_rate")
        break
    test.assert_test(1, True, f"received stream data {tot_len} is limited by prdcr rx_rate")
    break

# test.add_assertion( 2, "After the wait, the sampler can publish")
if x_28 in recs1:
    test.assert_test(2, True, "stream data received")
else:
    test.assert_test(2, False, "stream data not received")

# test.add_assertion( 3, "Sampler cannot publish all data (stream rate limit)")
while True: # will break
    if not set_2:
        test.assert_test(3, False, "empty stream data")
        break
    if not set_2 < set_full:
        test.assert_test(3, False, f"Got extra data: {set_2}")
        break
    tot_len = sum( len(o) for o in set_2 )
    if tot_len > 2*32 : # allow 2 times as the publish may cross 'the second' boundary
        test.assert_test(3, False, f"stream data received {tot_len} is greater than the stream rx_rate")
        break
    test.assert_test(3, True, f"received stream data {tot_len} is limited by stream rx_rate")
    break

# test.add_assertion( 4, "After the wait, the sampler can publish")
if x_28 in recs1:
    test.assert_test(4, True, "stream data received")
else:
    test.assert_test(4, False, "stream data not received")

# see at_exit()
