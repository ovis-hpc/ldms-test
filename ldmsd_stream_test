#!/usr/bin/env python3

"""
The script tests the ldmsd_stream_publish and ldmsd_stream_publish_file APIs
as well as the ldmsd_stream_subscribe and the ldmsd_stream_publish programs.

The script tests weather the APIs and program send the data correctly or not.
The data used in the test is smaller and larger than the maximum message length.

ldmsd_stream_publish ---> ldmsd_stream_subscribe
ldmsd_stream_publish ---> samplerd with the test_stream_sampler plugin
                                ||        |
                                ||        |
                                ||        V
                               agg with the test_stream_sampler plugin
"""

import argparse
import io
import itertools
import json
import logging
import os
import sys
import TADA
import time

from distutils.spawn import find_executable
from LDMS_Test import LDMSDCluster, D, process_args, add_common_args, \
                      cond_timedwait
from time import sleep

logging.basicConfig(format = "%(asctime)s %(name)s %(levelname)s %(message)s",
                    level = logging.INFO)

log = logging.getLogger(__name__)

# Exception class
class LDMSDStreamTestFail(Exception):
    pass

#### argument parsing #### -------------------------------------------
ap = argparse.ArgumentParser(description = "Run test scenario of 4 samplers " \
                             "(or more) -> 2 x agg-1 -> agg-2." )
add_common_args(ap)
args = ap.parse_args()
process_args(args)

#### config variables #### ------------------------------
LDMSD_PORT = 10000
LDMSD_XPRT = "sock"
DATA_ROOT = args.data_root

#### Constant variables #### ----------------------------
STREAM_NAME = "test_stream"
TADA_LIB = "/data/tada/lib"
TADA_SRC = "/tada-src"
DATA_DIR = "/data"

SUBSCRIBERS = [ "subscriber", "samplerd", "agg" ]
STREAM_TYPES = [ "json", "string" ]
DATA_SIZES = [ "large", "small" ]

STREAM_DATA = {"large": "/large-data.json",
               "small" : "/small-data.json"}

PORTS = { "json"   : LDMSD_PORT + 1,
          "string" : LDMSD_PORT + 2}

SAMPLE_SIZES = { "large": 100, "small" : 1000 }

STREAM_OUT = {}
for pg in SUBSCRIBERS:
    STREAM_OUT[pg] = {}
    for sz in DATA_SIZES:
        STREAM_OUT[pg][sz] = {}
        for t in STREAM_TYPES:
            STREAM_OUT[pg][sz][t] = "{}-{}-{}.out".format(pg, sz, t)

#### spec #### ------------------------------

SSH_DAEMON = [{ "name" : "sshd", "type" : "sshd" }]

spec = {
    "name" : args.clustername,
    "description" : "{}'s ldmsd_stream_test".format(args.user),
    "type" : "FVT",
    "templates" : {
        "ldmsd-daemon" : {
                "type" : "ldmsd",
                "listen" : [
                    { "port": LDMSD_PORT, "xprt" : LDMSD_XPRT}
                ],
        },
    },
    "nodes" : [
        {
            "hostname" : "publisher",
            "daemons" : SSH_DAEMON
        },
        {
            "hostname" : "subscriber",
            "daemons" : SSH_DAEMON
        },
        {
            "hostname" : "samplerd",
            "daemons" : SSH_DAEMON + [
                {
                    "name" : "samplerd",
                    "!extends" : "ldmsd-daemon"
                }
            ]
        },
        {
            "hostname" : "agg",
            "daemons" : SSH_DAEMON + [
                {
                    "name" : "agg",
                    "!extends" : "ldmsd-daemon",
                    "prdcrs" : [
                        {
                            "name" : "samplerd",
                            "host" : "samplerd",
                            "port" : LDMSD_PORT,
                            "xprt" : LDMSD_XPRT,
                            "type" : "active",
                            "interval" : 1000000
                        }
                    ],
                    "config" : [
                        "prdcr_start_regex regex=.*"
                    ]
                }
            ]
        }
    ],
    "cap_add" : [ "SYS_PTRACE", "SYS_ADMIN"],
    "image" : args.image,
    "ovis_prefix": args.prefix,
    "env" : {
        "LD_LIBRARY_PATH" : TADA_LIB + ":/opt/ovis/lib:/opt/ovis/lib64",
        "LDMSD_PLUGIN_LIBPATH" : TADA_LIB + ":/opt/ovis/lib/ovis-ldms:/opt/ovis/lib64/ovis-ldms",
        "PYTHONPATH" : "/opt/ovis/lib/python3.6/site-packages",
    },
    "mounts" : args.mount + [
        "{0}:{1}:ro".format(os.path.realpath(sys.path[0]), TADA_SRC),
        "{0}:{1}:rw".format(DATA_ROOT, DATA_DIR),
        ] + (["{0}:{0}:ro".format(args.src)] if args.src else [])
}

#### functions #### ------------------------------------------------------------
def get_assert_no():
    try:
        get_assert_no.counter += 1
    except AttributeError:
        get_assert_no.counter = 1
    return get_assert_no.counter

ASSERTIONS = {}
def add_assertion(_test, name, desc):
    ASSERTIONS[name] = get_assert_no()
    _test.add_assertion(ASSERTIONS[name], desc)

def rm(path):
    if os.path.exists(path):
        os.remove(path)

def get_msg_max(cont):
    script = \
        "#!/usr/bin/env python3\n" \
        "from ovis_ldms import ldms\n" \
        "x = ldms.Xprt()\n" \
        "print(x.msg_max)"
    rc, out = cont.pipe("/usr/bin/python3", script)
    if rc:
        raise RuntimeError("Failed to get maximum message length")
    return int(out)

def data_sz_get(data_sz, max_msg_len):
    if data_sz == "small":
        return int(max_msg_len / 2)
    elif data_sz == "large":
        return int(max_msg_len * 4)
    else:
        raise ValueError("Invalid data size {}".format(data_sz))

def stream_source_path_get(data_sz, is_host):
    if is_host:
        dpath = DATA_ROOT
    else:
        dpath = DATA_DIR
    return "{0}/{1}".format(dpath, STREAM_DATA[data_sz])

def stream_out_path_get(sub_name, data_sz, stream_type, is_host):
    if is_host:
        dpath = DATA_ROOT
    else:
        dpath = DATA_DIR
    return "{0}/{1}".format(dpath, STREAM_OUT[sub_name][data_sz][stream_type])

def prdcr_subscribe(cont):
    return cont.config_ldmsd(["prdcr_subscribe regex=.* stream={}".format(STREAM_NAME)])

def term_test_stream_sampler(cont):
    return cont.config_ldmsd(["term name=test_stream_sampler"])

def start_test_stream_sampler(cont, stream_type, data_sz):
    return cont.config_ldmsd(["load name=test_stream_sampler",
                            "config name=test_stream_sampler stream={sname} " \
                            "output={fout}".format(sname = STREAM_NAME,
                                fout=stream_out_path_get(cont.hostname,
                                        data_sz, stream_type, False))])

def start_subscriber(cont, port, fout):
    script = """
        set -e
        ldmsd_stream_subscribe -x {xprt} -p {port} -s {name} -f {fout} 2>&1 &
        sleep 1
        pgrep ldmsd_stream_subscribe
        grep ':\<{port:04x}\>' /proc/net/tcp
    """.format( xprt = LDMSD_XPRT,
                port = port,
                name = STREAM_NAME,
                fout = fout )
    cmd = "bash -c \"" \
          "ldmsd_stream_subscribe -x {xprt} -p {port} -s {name} -f {fout} >/dev/null 2>&1 & " \
          "sleep 1; " \
          "\"".format( xprt = LDMSD_XPRT,
                       port = port,
                       name = STREAM_NAME,
                       fout = fout)
    rc, out = cont.exec_run(cmd)
    if rc:
        raise RuntimeError("Failed to start ldmsd_stream_subscribe. Error {0}: {1}".format(rc, out))

def kill_subscriber(cont):
    rc, out = cont.exec_run("pgrep -f ldmsd_stream_subscribe")
    if rc:
        raise
    else:
        rc, out = cont.exec_run("kill {}".format(out))
        if rc:
            raise

def start_publisher(cont, host, port, stream_type, fin):
    cmd = "ldmsd_stream_publish -h {host} -x {xprt} -p {port} " \
                               "-s {name} -t {type} -f {fin} 2>&1" \
          .format( host = host,
                       xprt = LDMSD_XPRT,
                       port = port,
                       name = STREAM_NAME,
                       type = stream_type,
                       fin = fin)
    rc, out = cont.exec_run(cmd)
    if rc:
        raise RuntimeError("Failed to start ldmsd_stream_publish. Error {}".format(rc))

def subscriber_output_check(fout, fin, t, count):
    # Run subscriber_output_check script on the subscriber node
    cmd = "/tada-src/python/subscriber_output_check.py {} {} {} {}" \
          .format(fout, fin, t, count)
    rc, out = sub_cont.exec_run(cmd)
    if rc:
        raise LDMSDStreamTestFail(out)
    return True

def test_stream_sampler_check(cont, fin, fout, count):
    # Run test_stream_sampler_check on cont
    cmd = "/tada-src/python/stream_check.py {} {} {}" \
          .format(fin, fout, count)
    rc, out = cont.exec_run(cmd)
    if rc:
        raise LDMSDStreamTestFail(out)
    return True

# Prepare the test
for x in STREAM_OUT.values(): # subscribers
    for y in x.values(): # types
        for z in y.values(): # sizes
            rm(z)

#### test definition ### -------------------------------------------------------
test = TADA.Test(test_suite = "LDMSD",
                 test_type = "FVT",
                 test_name = "ldmsd_stream_test",
                 test_desc = "ldmsd_stream ...", #TODO
                 test_user = args.user,
                 commit_id = args.commit_id,
                 tada_addr = args.tada_addr)

# Add assertions
for t in STREAM_TYPES:
    for sz in DATA_SIZES:
        if sz == "small":
            _sz = "smaller"
        elif sz == "large":
            _sz = "larger"
        else:
            raise ValueError("Unknow data sizes - {}".format(sz))
        for sub in SUBSCRIBERS:
            if sub == "subscriber":
                _n = "ldmsd_stream_subscribe"
            else:
                _n = sub
            add_assertion(test, "{0}-{1}-{2}".format(sub, t, sz),
                  "{n} receives {sz} {t} streams".format(n=_n, sz=sz, t=t))

test.start()

cluster = LDMSDCluster.get(args.clustername, create = True, spec = spec)

# Build test_stream_sampler
cont = cluster.get_container("samplerd")
# Cleanup old files
rc, out = cont.exec_run("rm -f /data/*.out /data/*.json {}/*".format(TADA_LIB))
rc, out = cont.exec_run("make -C {0}/C BUILDDIR={1}".format(TADA_SRC, TADA_LIB))
if rc:
    raise RuntimeError("libtada build failed, output: {}".format(out))

def files_avail(files):
    for _cont in cluster.containers:
        cmd = " && ".join( "test -e {}/{}".format(TADA_LIB, s) for s in files)
        rc, out = _cont.exec_run(cmd)
        if rc:
            return False
    return True

def _lib_avail():
    return files_avail(
            ["libtada.so", "libtest_stream_sampler.so",
             "libtest_stream_sampler.so.0", "libutil.so",
             "test_ovis_ev", "test_ovis_json"]
        )

log.info("waiting for libraries to be available across all containers...")
cond_timedwait(_lib_avail, 60)
log.info("_lib_avail: {}".format(_lib_avail()))

# Start daemons on each node
cluster.start_daemons()

# Wait for daemons to be ready
time.sleep(5)

# Test ldmsd_stream_subscriber + publisher
def subscriber_case(sub_cont, pub_cont, hostname, stream_type, data_sz):
    global args
    global test

    log.info("test ldmsd_stream_subscribe with {0} {1} streams".format(data_sz, stream_type))
    D.cont_fin = cont_fin = stream_source_path_get(data_sz, False)
    D.host_fin = host_fin = stream_source_path_get(data_sz, True)
    D.cont_fout = cont_fout = stream_out_path_get(sub_cont.hostname, data_sz, stream_type, False)
    D.host_fout = host_fout = stream_out_path_get(sub_cont.hostname, data_sz, stream_type, True)
    D.stream_type = stream_type
    D.data_sz = data_sz
    D.sample_sz = SAMPLE_SIZES[data_sz]
    D.port = PORTS[stream_type]

    start_subscriber(sub_cont, PORTS[stream_type], cont_fout)
    log.info("--- Sending stream to ldmsd_stream_subscriber")
    for i in range(0, SAMPLE_SIZES[data_sz]):
        start_publisher(pub_cont, hostname, PORTS[stream_type], stream_type, cont_fin)
    def _fout_cond():
        f = open(host_fout)
        lines = f.readlines()
        if len(lines) != SAMPLE_SIZES[data_sz]:
            return False
        l0 = lines[0]
        for l in lines:
            if len(l) != len(l0):
                return False
        return True
    # cond_timedwait(_fout_cond, 5)

    log.info("--- Verifying the received streams")
    _assert_name = "subscriber-{0}-{1}".format(stream_type, data_sz)
    _verify_msg = "Verify all streams were received correctly"
    try:
        D.result = result = subscriber_output_check(cont_fout, cont_fin, stream_type, SAMPLE_SIZES[data_sz])
    except LDMSDStreamTestFail as e:
        test.assert_test(ASSERTIONS[_assert_name], False, "{}".format(e))
    except:
        raise
    else:
        test.assert_test(ASSERTIONS[_assert_name], result, _verify_msg)
    if not args.debug:
        rm(host_fout)
    kill_subscriber(sub_cont)

def ldmsd_case(pub_cont, samplerd_cont, agg_cont, stream_type, data_sz):
    global test
    global args

    log.info("test LDMSD with {0} {1} streams".format(data_sz, stream_type))
    host_fin = stream_source_path_get(data_sz, True)
    cont_fin = stream_source_path_get(data_sz, False)
    host_samplerd_fout = stream_out_path_get(samplerd_cont.hostname, data_sz, stream_type, True)
    cont_samplerd_fout = stream_out_path_get(samplerd_cont.hostname, data_sz, stream_type, False)
    host_agg_fout = stream_out_path_get(agg_cont.hostname, data_sz, stream_type, True)
    cont_agg_fout = stream_out_path_get(agg_cont.hostname, data_sz, stream_type, False)

    rc, out = start_test_stream_sampler(samplerd_cont, stream_type, data_sz)
    if rc:
        raise LDMSDStreamTestFail("samplerd: Failed to load/config/start test_stream_sampler")
    rc, out = start_test_stream_sampler(agg_cont, stream_type, data_sz)
    if rc:
        raise LDMSDStreamTestFail("agg: Failed to load/config/start test_stream_sampler")
    rc, out = prdcr_subscribe(agg_cont)
    if rc:
        raise LDMSDStreamTestFail("agg: Failed prdcr_subscribe")
    time.sleep(5)

    log.info("--- Sending stream to samplerd")
    for i in range(0, SAMPLE_SIZES[data_sz]):
        start_publisher(pub_cont, samplerd_cont.hostname, LDMSD_PORT, stream_type, cont_fin)
    time.sleep(5)

    # Test samplerd output
    log.info("--- Verifying the streams received by samplerd")
    _assert_name = "samplerd-{}-{}".format(stream_type, data_sz)
    _verify_msg = "Verify all streams were received correctly"
    try:
        result = test_stream_sampler_check(samplerd_cont, cont_fin, cont_samplerd_fout, SAMPLE_SIZES[data_sz])
    except LDMSDStreamTestFail as e:
        test.assert_test(ASSERTIONS[_assert_name], False, "{}".format(e))
    except:
        raise
    else:
        test.assert_test(ASSERTIONS[_assert_name], result, _verify_msg)

    # Test agg output
    log.info("--- Verifying the streams received by samplerd")
    _assert_name = "agg-{}-{}".format(stream_type, data_sz)
    _verify_msg = "Verify all streams were received correctly"
    try:
        result = test_stream_sampler_check(agg_cont, cont_fin, cont_agg_fout, SAMPLE_SIZES[data_sz])
    except LDMSDStreamTestFail as e:
        test.assert_test(ASSERTIONS[_assert_name], False, "{}".format(e))
    except:
        raise
    else:
        test.assert_test(ASSERTIONS[_assert_name], result, _verify_msg)

    if not args.debug:
        rm(host_samplerd_fout)
        rm(host_agg_fout)

sub_cont = cluster.get_container("subscriber")
pub_cont = cluster.get_container("publisher")
samplerd_cont = cluster.get_container("samplerd")
agg_cont = cluster.get_container("agg")

MAX_MSG_LEN = get_msg_max(sub_cont)

# Write stream data files
for sz in DATA_SIZES:
    with open(stream_source_path_get(sz, True), "w") as o:
        o.write("[\"")
        o.write("a" * (data_sz_get(sz, MAX_MSG_LEN)))
        o.write("\"]")
# Wait for input files to be available in all containers
_files = [ stream_source_path_get(sz, False) for sz in DATA_SIZES ]
cond_timedwait(lambda : files_avail(_files), 60)


# input("Press ENTER to continue")

# Test ldmsd_stream_subscribe
for t in STREAM_TYPES:
    for sz in DATA_SIZES:
        subscriber_case(sub_cont, pub_cont, sub_cont.hostname, t, sz)
        ldmsd_case(pub_cont, samplerd_cont, agg_cont, t, sz)

test.finish()
cluster.remove()
