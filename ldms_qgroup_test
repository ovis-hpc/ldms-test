#!/usr/bin/python3
#
# Test LDMS quota group (qgroup) feature (not `ldmsd`).

import os
import io
import re
import pwd
import sys
import json
import time
import atexit
import argparse
import TADA
import logging

from distutils.spawn import find_executable
from python.ldms_qgroup_util import QGROUP, parse_log
from LDMS_Test import LDMSDCluster, LDMSDContainer, process_args, \
                      add_common_args, PyPty

if __name__ != "__main__":
    raise RuntimeError("This should not be impoarted as a module.")

class Debug(object):
    pass
D = Debug()

logging.basicConfig(format = "%(asctime)s %(name)s %(levelname)s %(message)s",
                    level = logging.INFO)

log = logging.getLogger(__name__)

exec(open(os.getenv("PYTHONSTARTUP", "/dev/null")).read())

#### default values #### ---------------------------------------------
sbin_ldmsd = find_executable("ldmsd")
if sbin_ldmsd:
    default_prefix, a, b = sbin_ldmsd.rsplit('/', 2)
else:
    default_prefix = "/opt/ovis"

#### argument parsing #### -------------------------------------------
ap = argparse.ArgumentParser(description = "Test ldms_qgroup feature")
add_common_args(ap)
args = ap.parse_args()
process_args(args)

#### config variables #### ------------------------------
USER = args.user
PREFIX = args.prefix
COMMIT_ID = args.commit_id
SRC = args.src
CLUSTERNAME = args.clustername
DB = args.data_root
LDMSD_PORT = 10000

#### spec #### -------------------------------------------------------

NODES = [ f"samp{i}" for i in range(1, 7) ] + \
        [ f"agg1{i}" for i in range(1, 4) ] + \
        [ "agg2" ]

def munge_key(node):
    return '0'*1024

common_plugin_config = [
        "component_id=%component_id%",
        "instance=%hostname%/%plugin%",
        "producer=%hostname%",
    ]
spec = {
    "name" : CLUSTERNAME,
    "description" : "{}'s ldms_rail test cluster".format(USER),
    "type" : "NA",
    "templates" : { # generic template can apply to any object by "!extends"
    }, # templates
    "nodes" : [
        {
            "hostname" : node,
            "daemons" : [
                {
                    "name" : "sshd", # for debugging
                    "type" : "sshd",
                },
                {
                    "name" : "munged",
                    "type" : "munged",
                    "key"  : munge_key(node),
                },
            ],
        } for node in NODES
    ], # nodes

    "cap_add": [ "SYS_PTRACE", "SYS_ADMIN" ],
    "image": args.image,
    "ovis_prefix": PREFIX,
    "env" : { "FOO": "BAR" },
    "mounts": [
        "{}:/db:rw".format(DB),
        "{0}:{1}:ro".format(os.path.realpath(sys.path[0]), "/tada-src"),
    ] + args.mount +
    ( ["{0}:{0}:ro".format(SRC)] if SRC else [] ),
}

#### helper functions ####

def EXPECT(val, expected):
    if val != expected:
        raise RuntimeError("\n  EXPECTING: {}\n  GOT: {}".format(expected, val))

#### test definition ####

test = TADA.Test(test_suite = "LDMSD",
                 test_type = "FVT",
                 test_name = "ldms_qgroup_test",
                 test_desc = "Test quota group feature",
                 test_user = args.user,
                 commit_id = COMMIT_ID,
                 tada_addr = args.tada_addr)

test.add_assertion( 1, "Throughput without limit")
test.add_assertion( 2, "Data received after quota")
test.add_assertion( 3, "Throughput with limit")
test.add_assertion( 4, "Check data loss")
test.add_assertion( 5, "Check starvation")
test.add_assertion( 6, "Single publisher saturation test")

cluster = None
test.start()

@atexit.register
def at_exit():
    rc = test.finish()
    if cluster is not None:
        cluster.remove()
    os._exit(rc)


log.info("-- Get or create the cluster --")
cluster = LDMSDCluster.get(spec["name"], create = True, spec = spec)

samp1 = cluster.get_container("samp1")
samp2 = cluster.get_container("samp2")
samp3 = cluster.get_container("samp3")
samp4 = cluster.get_container("samp4")
samp5 = cluster.get_container("samp5")
samp6 = cluster.get_container("samp6")

agg11 = cluster.get_container("agg11")
agg12 = cluster.get_container("agg12")
agg13 = cluster.get_container("agg13")

agg2  = cluster.get_container("agg2")

log.info("-- Start daemons --")
cluster.start_daemons()
cluster.make_known_hosts()

log.info("... wait a bit to make sure daemons are up")
time.sleep(2)

PY_APP_CMD  = "/tada-src/python/ldms_qgroup_app.py"
PY_SAMP_CMD = "/tada-src/python/ldms_qgroup_samp.py"
PY_AGG1_CMD = "/tada-src/python/ldms_qgroup_agg1.py"
PY_AGG2_CMD = "/tada-src/python/ldms_qgroup_agg2.py"

# start samplers first
py_samp1 = PyPty(samp1, PY_SAMP_CMD)
py_samp2 = PyPty(samp2, PY_SAMP_CMD)
py_samp3 = PyPty(samp3, PY_SAMP_CMD)
py_samp4 = PyPty(samp4, PY_SAMP_CMD)
py_samp5 = PyPty(samp5, PY_SAMP_CMD)
py_samp6 = PyPty(samp6, PY_SAMP_CMD)

time.sleep(1)

MANUAL_AGG1 = False

# start agg1's
if MANUAL_AGG1:
    input("Manually start aggs under gdb and hit ENTER to continue ...")
else:
    py_agg11 = PyPty(agg11, PY_AGG1_CMD)
    py_agg12 = PyPty(agg12, PY_AGG1_CMD)
    py_agg13 = PyPty(agg13, PY_AGG1_CMD)

time.sleep(1)

# start agg2's
py_agg2 = PyPty(agg2, PY_AGG2_CMD)

time.sleep(1)

# start app's
py_app1 = PyPty(samp1, PY_APP_CMD)
py_app2 = PyPty(samp2, PY_APP_CMD)
py_app3 = PyPty(samp3, PY_APP_CMD)
py_app4 = PyPty(samp4, PY_APP_CMD)
py_app5 = PyPty(samp5, PY_APP_CMD)
py_app6 = PyPty(samp6, PY_APP_CMD)

py_apps = [ py_app1, py_app2, py_app3, py_app4, py_app5, py_app6 ]

time.sleep(1)

log.info("-- starting app publisher --")
for p in py_apps:
    p.cmd('p.start()')

def qgroup_start():
    if MANUAL_AGG1:
        input("Manually start qgroup and hit ENTER to continue ...")
    else:
        py_agg11.cmd('ldms.qgroup.start()')
        py_agg12.cmd('ldms.qgroup.start()')
        py_agg13.cmd('ldms.qgroup.start()')
    for p in py_apps:
        p.cmd('slog.info("== qgroup begin ==")')

log.info("-- Wait a minute to get data flow (without limit) --")
time.sleep(60)
out1 = py_agg2.cmd('st.details()')

qgroup_start()
log.info("-- Wait a minute to get data flow (with limit) --")
time.sleep(90)
out2 = py_agg2.cmd('st.details()')

log.info("-- stopping app publisher --")
for p in py_apps:
    p.cmd('p.stop()')

log.info("-- wait a bit to make sure the published data is flushed --")
time.sleep(5)

o1 = eval(out1)
o2 = eval(out2)

cfg_bps = 3 * QGROUP.CFG_QUOTA / (QGROUP.CFG_RESET_USEC * 1e-6)

log.info("-- collecting logs --")

samp_msgs = list()
for samp in [ samp1, samp2, samp3, samp4, samp5, samp6 ]:
    out = samp.read_file('/var/log/app.log')
    msgs = [ parse_log(l) for l in out.splitlines() ]
    samp_msgs.append(msgs)

agg2_out = agg2.read_file('/var/log/agg.log')
agg2_msgs = [ parse_log(l) for l in agg2_out.splitlines() ]

# collect messages from app and agg2
app_data = list()
rcv_data = list()
before_msgs = list()
after_msgs = list()
after_count = list()

idx = 0
for msgs in samp_msgs:
    lst = before_msgs # messages before qgroup
    do_count = False
    count = 0
    for m in msgs:
        o = m.get('other')
        if o and 'qgroup begin' in o:
            # switch to 'after_msgs' after 'qgroup begin'
            lst = after_msgs
            do_count = True
        if m.get('pub_name') == 'app':
            app_data.append(m.get('pub_data'))
            lst.append(m)
            count += do_count
    after_count.append(count)

for m in agg2_msgs:
    if m.get('recv_name') == 'app':
        rcv_data.append(m.get('recv_data'))

app_data.sort()
rcv_data.sort()

# jtest.add_assertion( 1, "Throughput without limit")
while True:
    bps1 = o1[30][0]/30
    if bps1 < cfg_bps:
        test.assert_test(1, False, f"bps1({bps1}) < cfg_bps({cfg_bps})")
        break
    if len(o1[30][1]) < 6:
        test.assert_test(1, False, f"data missing")
        break
    for k, v in o1[30][1].items():
        if not v:
            test.assert_test(1, False, f"no data from {k}")
            break
    else:
        test.assert_test(1, True, f"bps: {bps1}, OK")
    break

# test.add_assertion( 2, "Data received after quota")
while True:
    for c in after_count:
        if not c:
            test.assert_test(2, False,
                f"message not delivered after quota, count by source: {after_count}")
            break
    else:
        test.assert_test(2, True, "OK")
    break

# test.add_assertion( 3, "Throughput with limit")
while True:
    bps2 = o2[30][0]/30
    if bps2 > cfg_bps:
        test.assert_test(3, False, f"bps2({bps2}) exceeds limit cfg_bps({cfg_bps})")
        break
    if len(o2[30][1]) < 6:
        test.assert_test(3, False, f"data missing")
        break
    for k, v in o2[30][1].items():
        if not v:
            test.assert_test(3, False, f"no data from {k}")
            break
    test.assert_test(3, True, f"bps: {bps2}, limit: {cfg_bps}, OK")
    break

#test.add_assertion( 4, "Check data loss")
while True: # will break
    if app_data != rcv_data:
        test.assert_test( 4, False, "data missing")
    test.assert_test( 4, True, "No data missing")
    break

#test.add_assertion( 5, "Check starvation")
while True:
    mx = max(after_count)
    thr = mx * 0.1
    df = [ mx - v for v in after_count ]
    for d in df:
        if d > thr:
            test.assert_test( 5, False,
                f"starvation detected, message count by src: {after_count}")
            break
    else:
        test.assert_test( 5, True, "OK")
    break

#test.add_assertion( 6, "Single publisher saturation test")
while True:
    p = py_app1
    log.info("-- ramp up app1 for saturation test --")
    p.cmd('p.interval = 0.05')
    log.info("-- starting app1 publisher again (for saturation test) --")
    p.cmd('p.start()')
    log.info("-- Wait a minute to get data flow (with limit) --")
    time.sleep(60)
    out2 = py_agg2.cmd('st.details()')
    log.info("-- stopping app1 publisher --")
    p.cmd('p.stop()')
    sat_bps = cfg_bps - 2*QGROUP.CFG_ASK_MARK
    sat_bps_80 = 0.8 * sat_bps
    o2 = eval(out2)
    bps30 = o2[30][0] / 30
    if bps30 < sat_bps_80 or sat_bps < bps30:
        test.assert_test( 6, False, f"bad saturation bps: {bps30} fall out of"
                                    f" expected range [{sat_bps_80}, {sat_bps}]"
                                    f" (cfg_bps: {cfg_bps})")
        break
    test.assert_test( 6, True, f"good saturation bps: {bps30} in"
                               f" expected range [{sat_bps_80}, {sat_bps}]"
                               f" (cfg_bps: {cfg_bps})")
    break
