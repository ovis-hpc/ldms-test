#!/usr/bin/env python3
from __future__ import print_function
import re
import argparse
import os
import sys
import pwd
import TADA
import time
import json
import logging
import atexit
import shutil

from io import StringIO

from distutils.spawn import find_executable
from LDMS_Test import LDMSDCluster, D, process_args, add_common_args, read_msg, \
                        is_ldmsd_version_4

logging.basicConfig(format = "%(asctime)s %(name)s %(levelname)s %(message)s",
                    level = logging.INFO)

log = logging.getLogger(__name__)

TADA_LIB = "/data/tada/lib"
TADA_SRC = "/tada-src"

spec = {
    "name" : "REPLACE_ME",
    "description" : "cluster for prdcr_subscribe_test",
    "templates" : { # generic template can apply to any object by "!extends"
        "compute-node" : {
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "munged",
                    "type" : "munged",
                },
                {
                    "name" : "sampler-daemon",
                    "requires" : [ "munged" ],
                    "!extends" : "ldmsd-sampler",
                },
            ],
        },
        "ldmsd-sampler" : {
            "!extends" : "ldmsd-base",
            "samplers" : [
                {
                    "plugin" : "test_stream_sampler",
                    "interval" : 1000000,
                    "offset" : 0,
                    "config" : [
                        "component_id=%component_id%",
                        "instance=%hostname%/%plugin%",
                        "producer=%hostname%",
                        "stream=test_stream",
                        "output=/data/%hostname%.out"
                    ]
                },
            ],
        },
        "ldmsd-base" : {
            "type" : "ldmsd",
            "listen_port" : 10000,
            "listen_xprt" : "sock",
            "listen_auth" : "munge",
        },
        "prdcr" : {
            "host" : "%name%",
            "port" : 10000,
            "xprt" : "sock",
            "type" : "active",
            "interval" : 1000000,
        },
    },
    "nodes" : [
        {
            "hostname" : "stream-sampler-1",
            "component_id" : 10001,
            "!extends" : "compute-node",
        },
        {
            "hostname" : "stream-sampler-2",
            "component_id" : 10002,
            "!extends" : "compute-node",
        },
        {
            "hostname" : "agg-1",
            "component_id" : 10003,
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "munged",
                    "type" : "munged",
                },
                {
                    "name" : "aggregator",
                    "!extends" : "ldmsd-base",
                    "listen_port" : 20000, # override
                    "prdcrs" : [ # these producers will turn into `prdcr_add`
                        {
                            "name" : "stream-sampler-1",
                            "!extends" : "prdcr",
                        },
                        {
                            "name" : "stream-sampler-2",
                            "!extends" : "prdcr",
                        },
                    ],
                    "config" : [ # additional config applied after prdcrs
                        "prdcr_subscribe regex=.* stream=test_stream",
                        "prdcr_start_regex regex=.*",
                    ],
                },
            ]
        },
        {
            "hostname" : "agg-2",
            "component_id" : 10004,
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "munged",
                    "type" : "munged",
                },
                {
                    "name" : "aggregator",
                    "!extends" : "ldmsd-base",
                    "listen_port" : 20000, # override
                    "samplers" : [
                        {
                            "plugin" : "test_stream_sampler",
                            "interval" : 1000000,
                            "offset" : 0,
                            "config" : [
                                "component_id=%component_id%",
                                "instance=%hostname%/%plugin%",
                                "producer=%hostname%",
                                "stream=test_stream",
                                "output=/data/%hostname%.out"
                            ]
                        },
                    ],
                    "prdcrs" : [ # these producers will turn into `prdcr_add`
                        {
                            "name" : "agg-1",
                            "!extends" : "prdcr",
                            "port" : 20000,
                        },
                    ],
                    "config" : [ # additional config applied after prdcrs
                        "prdcr_subscribe regex=.* stream=test_stream",
                        "prdcr_start_regex regex=.*",
                    ],
                },
            ]
        },
    ],

    #"image": "ovis-centos-build:slurm",
    "cap_add": [ "SYS_PTRACE" ],
    "image": None,
    "ovis_prefix": "REPLACE_ME",
    "env" : {
        "LD_LIBRARY_PATH": "/data/tada/lib:/opt/ovis/lib:/opt/ovis/lib64",
        "LDMSD_PLUGIN_LIBPATH": "/data/tada/lib:/opt/ovis/lib/ovis-ldms:/opt/ovis/lib64/ovis-ldms",
    },
    "mounts": [ "{}:/tada-src:ro".format(os.path.realpath(sys.path[0])) ],
}

def rm(path):
    if os.path.exists(path):
        os.remove(path)

def prdcr_start_regex(agg, regex_str):
    if is_ldmsd_version_4(agg.ldmsd_version):
        txt = "prdcr_start_regex regex={}".format(regex_str)
    else:
        obj = { "request": "update",
                "id": 1,
                "schema": "prdcr",
                "enabled": True,
                "re": [regex_str]}
        txt = "json " + json.dumps(obj)
    return agg.config_ldmsd([txt])

def prdcr_stop_regex(agg, regex_str):
    if is_ldmsd_version_4(agg.ldmsd_version):
        txt = "prdcr_stop_regex regex={}".format(regex_str)
    else:
        obj = { "request": "update",
                "id": 1,
                "schema": "prdcr",
                "enabled": False,
                "re": [regex_str]}
        txt = "json " + json.dumps(obj)
    return agg.config_ldmsd([txt])

def prdcr_unsubscribe(node, regex, stream):
    """Tells ldmsd on `node` to prdcr_unsubscribe regex=`regex` stream=`stream`"""
    if is_ldmsd_version_4(node.ldmsd_version):
        txt = "prdcr_unsubscribe regex={} stream={}".format(regex, stream)
    else:
        raise NotImplementedError("prdcr_unsubscribe is not supported (yet) in v5")
    return node.config_ldmsd([txt])

def stream_client_dump(node):
    """Dump stream clients in ldmsd on node as a list of (stream_name, cb_fn, cb_ctxt) tuples"""
    if is_ldmsd_version_4(node.ldmsd_version):
        txt = "stream_client_dump"
    else:
        raise NotImplementedError("stream_client_dump is not supported (yet) in v5")
    rc, out = node.config_ldmsd([txt])
    lines = out.split("\n")[2:]
    lst = []
    for l in lines:
        if l == "":
            continue
        x = l.strip().split(None, 1)
        if len(x) == 1:
            stream_name = x[0]
        else:
            (ctxt, cb_fn) = (x[0], x[1])
            lst.append((stream_name, cb_fn, ctxt))
    return lst

def verify_msg(test, assert_no, msg, json_data, err_text):
    if msg["type"] == "json":
        if msg["obj"] != json_data:
            test.assert_test(assert_no, False, err_text)
            return False
    elif msg["type"] == "string":
        if msg["text"] != json.dumps(json_data):
            test.assert_test(assert_no, False, err_text)
            return False
    else:
        test.assert_test(assert_no, False,
                         "Unknown message type: {}".format(msg["type"]))
        return False
    return True

def start_publisher(cont, host, port, stream_type, fin):
    cmd = "ldmsd_stream_publish -h {host} -x {xprt} -p {port} -a munge " \
                               "-s {name} -t {type} -f {fin} 2>&1" \
          .format( host = host,
                       xprt = "sock",
                       port = port,
                       name = "test_stream",
                       type = stream_type,
                       fin = fin)
    rc, out = cont.exec_run(cmd)
    if rc:
        raise RuntimeError("Failed to start ldmsd_stream_publish. Error {}".format(rc))

if __name__ == "__main__":
    if sys.flags.interactive:
        exec(open(os.getenv("PYTHONSTARTUP", "/dev/null")).read())
    parser = argparse.ArgumentParser(description="ldmsd_stream_publish/subscribe FVT test")
    add_common_args(parser)
    args = parser.parse_args()
    process_args(args)

    clustername = args.clustername
    COMMIT_ID = args.commit_id

    spec["ovis_prefix"] = args.prefix
    spec["name"] = clustername
    spec["mounts"] += [ "{}:/data:rw".format(args.data_root) ]
    spec["mounts"] += args.mount
    if args.src:
        spec["mounts"] += [ "{0}:{0}:ro".format(args.src) ]
    spec["env"]["TADA_USER"] = args.user
    spec["env"]["TADA_ADDR"] = args.tada_addr
    spec["image"] = args.image

    # remove existing files
    rm(args.data_root + "/stream-sampler-1.out")
    rm(args.data_root + "/stream-sampler-2.out")
    rm(args.data_root + "/agg-2.out")

    # test = TADA.Test(args.cfg, args.prefix, args.data_root, args.tada_addr)
    test = TADA.Test(test_suite = "LDMSD",
                     test_type = "SVT",
                     test_name = "prdcr_subscribe_test",
                     test_desc = "LDMSD stream system verification test",
                     test_user = args.user,
                     commit_id = COMMIT_ID,
                     tada_addr = args.tada_addr)
    test.add_assertion(0, 'ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds')
    test.add_assertion(1, 'ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds')
    test.add_assertion(2, 'ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds')
    test.add_assertion(3, 'ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds')
    test.add_assertion(4, 'ldmsd_stream data check on agg-2')

    test.add_assertion(5, 'Stopping the producers succeeds')
    test.add_assertion(6, 'Restarting the producers succeeds')

    test.add_assertion(7, 'JSON stream data resumes after producer restart on stream-sampler-1')
    test.add_assertion(8, 'STRING stream data resumes after producer rerestart on stream-sampler-1')
    test.add_assertion(9, 'JSON stream data resumes after producer restart on stream-sampler-2')
    test.add_assertion(10, 'STRING stream data resumes after producer rerestart on stream-sampler-2')
    test.add_assertion(11, 'ldmsd_stream data resume check on agg-2')

    test.add_assertion(12, 'stream-sampler-1 is not running')
    test.add_assertion(13, 'stream-sampler-1 has restarted')
    test.add_assertion(14, 'JSON stream data resumes after stream-sampler-1 restart')
    test.add_assertion(15, 'STRING stream data resumes after stream-sampler-1 restart')
    test.add_assertion(16, 'ldmsd_stream data check on agg-2 after stream-sampler-1 restart')

    test.add_assertion(17, 'agg-1 unsubscribes stream-sampler-1')
    test.add_assertion(18, 'agg-1 receives data only from stream-sampler-2')

    cluster = None
    # Tell the TADA infrastructure that the test is starting
    test.start()

    @atexit.register
    def at_exit():
        rc = test.finish()
        # cleanup data
        flist = [ "agg-2.out", "stream-sampler-1.out", "stream-sampler-2.out",
                  "Stream_Test-data.json", "tada/" ]
        flist = [ "/{}/{}".format(args.data_root, x) for x in flist ]
        for f in flist:
            shutil.rmtree(f, ignore_errors = True)
        if cluster is not None:
            cluster.remove()
        os._exit(rc)

    # Create the containers required to ruyn the test
    cluster = LDMSDCluster.get(clustername, create = True, spec = spec)

    # Build libtest_stream_sampler before starting ldmsd
    cont = cluster.get_container("agg-1")
    # Cleanup old files
    rc, out = cont.exec_run("rm -f /data/*.out /data/*.json {}/*".format(TADA_LIB))
    rc, out = cont.exec_run("make -C {0}/C BUILDDIR={1}".format(TADA_SRC, TADA_LIB))
    if rc:
        raise RuntimeError("libtada build failed, output: {}".format(out))

    # Start all the LDMS Daemons configured in each container. NB: LDMSD can also be started
    # individually with start_daemon('hostname')
    cluster.start_daemons()

    # Give the daemons a few seconds to start
    time.sleep(5)

    # Create the test data
    data = { "gen" : 1,
             "schema" : "stream_test",
             "timestamp" : 1559242264,
             "data" : {
                 "id" : 12345,
                 "list" : [ 1, 2, 3, 4 ]
             }
         }
    text_data = json.dumps(data)
    data_file = '/data/Stream_Test-data.json'

    assert_no = 0
    for host in [ 'stream-sampler-1', 'stream-sampler-2' ]:
        cont = cluster.get_container(host)
        cont.write_file(data_file, text_data)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "json", data_file)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "string", data_file)

    time.sleep(2)

    # data verification
    samp1 = cluster.get_container("stream-sampler-1")
    samp2 = cluster.get_container("stream-sampler-2")
    agg1 = cluster.get_container("agg-1")
    agg2 = cluster.get_container("agg-2")

    samp1_out_txt = samp1.read_file("/data/stream-sampler-1.out")
    samp2_out_txt = samp2.read_file("/data/stream-sampler-2.out")
    agg2_out_txt = agg2.read_file("/data/agg-2.out")

    samp1_out = StringIO(samp1_out_txt)
    samp2_out = StringIO(samp2_out_txt)
    agg2_out = StringIO(agg2_out_txt)

    # Verify samp1
    for x in range(0, 2):
        msg = read_msg(samp1_out)
        if msg["type"] == "json":
            test.assert_test(0, msg["obj"] == data, "verify JSON data")
        elif msg["type"] == "string":
            test.assert_test(1, msg["text"] == text_data, "verify STRING data")
        else:
            raise RuntimeError("Bad message type")

    # Verify samp2
    for x in range(0, 2):
        msg = read_msg(samp2_out)
        if msg["type"] == "json":
            test.assert_test(2, msg["obj"] == data, "verify JSON data")
        elif msg["type"] == "string":
            test.assert_test(3, msg["text"] == text_data, "verify STRING data")
        else:
            raise RuntimeError("Bad message type")

    # Verify agg2
    text_count = 0
    json_count = 0
    _verify = True
    _verify_msg = "agg2 stream data verification"
    for x in range(0, 4):
        msg = read_msg(agg2_out)
        if msg["type"] == "string":
            text_count += 1
            _verify &= (msg["text"] == text_data)
        elif msg["type"] == "json":
            json_count += 1
            _verify &= (msg["obj"] == data)
        else:
            _verify = False
            _verify_msg = "Bad message type: {}".format(msg["type"])
    if _verify and (text_count != 2 or json_count != 2):
        _verify = False
        _verify_msg = "Message mismatch"
    test.assert_test(4, _verify, _verify_msg)

    agg_h = cluster.get_container('agg-1')
    rc, out = prdcr_stop_regex(agg_h, ".*")
    if is_ldmsd_version_4(agg_h.ldmsd_version):
        test.assert_test(5, (len(out) == 0), out)
    else:
        rsp = json.loads(out)
        test.assert_test(5, rsp["status"] == 0, rsp)

    rc, out = prdcr_start_regex(agg_h, ".*")
    if is_ldmsd_version_4(agg_h.ldmsd_version):
        test.assert_test(6, (len(out) == 0), out)
    else:
        rsp = json.loads(out)
        test.assert_test(6, rsp["status"] == 0, rsp)

    # give them time to reconnect before publishing new data
    time.sleep(5)

    # second set of data
    data = { "gen" : 2,
             "schema" : "stream_test",
             "timestamp" : 1559242274,
             "data" : {
                 "id" : 23456,
                 "list" : [ 1, 2, 3, 4, 5, 6 ]
             }
         }
    text_data = json.dumps(data)

    for host in [ 'stream-sampler-1', 'stream-sampler-2' ]:
        cont = cluster.get_container(host)
        cont.write_file(data_file, text_data)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "json", data_file)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "string", data_file)

    time.sleep(2)

    samp1_out_txt2 = samp1.read_file("/data/stream-sampler-1.out")
    samp2_out_txt2 = samp2.read_file("/data/stream-sampler-2.out")
    agg2_out_txt2 = agg2.read_file("/data/agg-2.out")

    samp1_out = StringIO(samp1_out_txt2)
    samp2_out = StringIO(samp2_out_txt2)
    agg2_out = StringIO(agg2_out_txt2)

    samp1_out.seek(len(samp1_out_txt))
    samp2_out.seek(len(samp2_out_txt))
    agg2_out.seek(len(agg2_out_txt))

    # Verify samp1
    for x in range(0, 2):
        msg = read_msg(samp1_out)
        if msg["type"] == "json":
            test.assert_test(7, msg["obj"] == data, "verify JSON data")
        elif msg["type"] == "string":
            test.assert_test(8, msg["text"] == text_data, "verify STRING data")
        else:
            raise RuntimeError("Bad message type")

    # Verify samp2
    for x in range(0, 2):
        msg = read_msg(samp2_out)
        if msg["type"] == "json":
            test.assert_test(9, msg["obj"] == data, "verify JSON data")
        elif msg["type"] == "string":
            test.assert_test(10, msg["text"] == text_data, "verify STRING data")
        else:
            raise RuntimeError("Bad message type")

    # Verify agg2
    text_count = 0
    json_count = 0
    _verify = True
    _verify_msg = "agg2 stream data verification"
    for x in range(0, 4):
        msg = read_msg(agg2_out)
        if msg["type"] == "string":
            text_count += 1
            _verify &= (msg["text"] == text_data)
        elif msg["type"] == "json":
            json_count += 1
            _verify &= (msg["obj"] == data)
        else:
            _verify = False
            _verify_msg = "Bad message type: {}".format(msg["type"])
    if _verify and (text_count != 2 or json_count != 2):
        _verify = False
        _verify_msg = "Message mismatch"
    test.assert_test(11, _verify, _verify_msg)

    cont = cluster.get_container('stream-sampler-1')

    cont.kill_ldmsd()
    time.sleep(1)
    running = cont.pgrepc('ldmsd')
    test.assert_test(12, (running == False), '(running == False)')

    cont.start_ldmsd()
    time.sleep(1)
    running = cont.pgrepc('ldmsd')
    test.assert_test(13, (running == True), '(running == True)')

    time.sleep(5) # allow some time for prdcr to reconnect

    data = { "gen" : 3,
             "schema" : "stream_test",
             "timestamp" : 1559250000,
             "data" : {
                 "id" : 78910,
                 "list" : [ 1  ]
             }
         }
    text_data = json.dumps(data)

    for host in [ 'stream-sampler-1' ]:
        cont = cluster.get_container(host)
        cont.write_file(data_file, text_data)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "json", data_file)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "string", data_file)

    time.sleep(2)

    # samp1 was reset
    samp1_out_txt3 = samp1.read_file("/data/stream-sampler-1.out")
    agg2_out_txt3 = agg2.read_file("/data/agg-2.out")

    samp1_out = StringIO(samp1_out_txt3)
    agg2_out = StringIO(agg2_out_txt3)

    agg2_out.seek(len(agg2_out_txt2))

    # Verify samp1
    for x in range(0, 2):
        msg = read_msg(samp1_out)
        if msg["type"] == "json":
            test.assert_test(14, msg["obj"] == data, "verify JSON data")
        elif msg["type"] == "string":
            test.assert_test(15, msg["text"] == text_data, "verify STRING data")
        else:
            raise RuntimeError("Bad message type")

    # Verify agg2
    text_count = 0
    json_count = 0
    for x in range(0, 2):
        msg = read_msg(agg2_out)
        if msg["type"] == "string":
            text_count += 1
            _verify &= (msg["text"] == text_data)
        elif msg["type"] == "json":
            json_count += 1
            _verify &= (msg["obj"] == data)
        else:
            _verify = False
            _verify_msg = "Bad message type: {}".format(msg["type"])
    if _verify and (text_count != 1 or json_count != 1):
        _verify = False
        _verify_msg = "Message mismatch"
    test.assert_test(16, _verify, _verify_msg)

    #test.add_assertion(17, 'agg-1 unsubscribes stream-sampler-1')
    rc, out = prdcr_unsubscribe(agg1, regex='stream-sampler-1', stream='test_stream')
    if is_ldmsd_version_4(agg_h.ldmsd_version):
        test.assert_test(17, (len(out) == 0), out)
    else:
        rsp = json.loads(out)
        test.assert_test(17, rsp["status"] == 0, rsp)

    #test.add_assertion(18, 'agg-1 receives data only from stream-sampler-2')

    samp1_out_txt_pre = samp1.read_file("/data/stream-sampler-1.out")
    samp2_out_txt_pre = samp2.read_file("/data/stream-sampler-2.out")
    agg2_out_txt_pre = agg2.read_file("/data/agg-2.out")

    data = {
            'stream-sampler-1': { "gen" : 4,
                 "schema" : "stream_test",
                 "timestamp" : 1559242274,
                 "data" : {
                     "id" : 23456,
                     "list" : [ 1, 1, 1, 1, 1, 1 ]
                 }
             },
            'stream-sampler-2': { "gen" : 4,
                 "schema" : "stream_test",
                 "timestamp" : 1559242274,
                 "data" : {
                     "id" : 23456,
                     "list" : [ 2, 2, 2, 2, 2, 2 ]
                 }
             },
         }

    for host in [ 'stream-sampler-1', 'stream-sampler-2' ]:
        _data = data[host]
        text_data = json.dumps(_data)
        cont = cluster.get_container(host)
        cont.write_file(data_file, text_data)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "json", data_file)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "string", data_file)

    time.sleep(2)

    samp1_out_txt_post = samp1.read_file("/data/stream-sampler-1.out")
    samp2_out_txt_post = samp2.read_file("/data/stream-sampler-2.out")
    agg2_out_txt_post = agg2.read_file("/data/agg-2.out")

    samp1_out = StringIO(samp1_out_txt_post)
    samp2_out = StringIO(samp2_out_txt_post)
    agg2_out = StringIO(agg2_out_txt_post)

    samp1_out.seek(len(samp1_out_txt_pre))
    samp2_out.seek(len(samp2_out_txt_pre))
    agg2_out.seek(len(agg2_out_txt_pre))

    while True: # this will break
        # samp1
        _data = data["stream-sampler-1"]
        _text_data = json.dumps(_data)
        # json and string
        msg = read_msg(samp1_out)
        if not verify_msg(test, 18, msg, _data, "stream-sampler-1 data verification failed"):
            break
        msg = read_msg(samp1_out)
        if not verify_msg(test, 18, msg, _data, "stream-sampler-1 data verification failed"):
            break
        # samp2
        _data = data["stream-sampler-2"]
        _text_data = json.dumps(_data)
        # json and string
        msg = read_msg(samp2_out)
        if not verify_msg(test, 18, msg, _data, "stream-sampler-2 data verification failed"):
            break
        msg = read_msg(samp2_out)
        if not verify_msg(test, 18, msg, _data, "stream-sampler-2 data verification failed"):
            break
        # agg-2 - expects only 2 messages from samp2
        _data = data["stream-sampler-2"]
        _text_data = json.dumps(_data)
        # json and string
        msg = read_msg(agg2_out)
        if not verify_msg(test, 18, msg, _data, "agg-2 data verification failed"):
            break
        msg = read_msg(agg2_out)
        if not verify_msg(test, 18, msg, _data, "agg-2 data verification failed"):
            break
        if agg2_out.tell() != len(agg2_out_txt_post):
            test.assert_test(18, False, "agg-2 has extra stream data")
            break
        test.assert_test(18, True, "data verified")
        break

# see at_exit()
