#!/usr/bin/env python3
from __future__ import print_function
import re
import argparse
import os
import sys
import pwd
import TADA
import time
import json
import logging

from io import StringIO

from distutils.spawn import find_executable
from LDMS_Test import LDMSDCluster, D, process_args, add_common_args, read_msg, \
                        is_ldmsd_version_4

logging.basicConfig(format = "%(asctime)s %(name)s %(levelname)s %(message)s",
                    level = logging.INFO)

log = logging.getLogger(__name__)

TADA_LIB = "/data/tada/lib"
TADA_SRC = "/tada-src"

spec = {
    "name" : "REPLACE_ME",
    "description" : "cluster for prdcr_subscribe_test",
    "templates" : { # generic template can apply to any object by "!extends"
        "compute-node" : {
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "munged",
                    "type" : "munged",
                },
                {
                    "name" : "sampler-daemon",
                    "requires" : [ "munged" ],
                    "!extends" : "ldmsd-sampler",
                },
            ],
        },
        "ldmsd-sampler" : {
            "!extends" : "ldmsd-base",
            "samplers" : [
                {
                    "plugin" : "test_stream_sampler",
                    "interval" : 1000000,
                    "offset" : 0,
                    "config" : [
                        "component_id=%component_id%",
                        "instance=%hostname%/%plugin%",
                        "producer=%hostname%",
                        "stream=test_stream",
                        "output=/data/%hostname%.out"
                    ]
                },
            ],
        },
        "ldmsd-base" : {
            "type" : "ldmsd",
            "listen_port" : 10000,
            "listen_xprt" : "sock",
            "listen_auth" : "munge",
        },
        "prdcr" : {
            "host" : "%name%",
            "port" : 10000,
            "xprt" : "sock",
            "type" : "active",
            "interval" : 1000000,
        },
    },
    "nodes" : [
        {
            "hostname" : "stream-sampler-1",
            "component_id" : 10001,
            "!extends" : "compute-node",
        },
        {
            "hostname" : "stream-sampler-2",
            "component_id" : 10002,
            "!extends" : "compute-node",
        },
        {
            "hostname" : "agg-1",
            "component_id" : 10003,
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "munged",
                    "type" : "munged",
                },
                {
                    "name" : "aggregator",
                    "!extends" : "ldmsd-base",
                    "listen_port" : 20000, # override
                    "prdcrs" : [ # these producers will turn into `prdcr_add`
                        {
                            "name" : "stream-sampler-1",
                            "!extends" : "prdcr",
                        },
                        {
                            "name" : "stream-sampler-2",
                            "!extends" : "prdcr",
                        },
                    ],
                    "config" : [ # additional config applied after prdcrs
                        "prdcr_subscribe regex=.* stream=test_stream",
                        "prdcr_start_regex regex=.*",
                    ],
                },
            ]
        },
        {
            "hostname" : "agg-2",
            "component_id" : 10004,
            "daemons" : [
                {
                    "name" : "sshd",
                    "type" : "sshd",
                },
                {
                    "name" : "munged",
                    "type" : "munged",
                },
                {
                    "name" : "aggregator",
                    "!extends" : "ldmsd-base",
                    "listen_port" : 20000, # override
                    "samplers" : [
                        {
                            "plugin" : "test_stream_sampler",
                            "interval" : 1000000,
                            "offset" : 0,
                            "config" : [
                                "component_id=%component_id%",
                                "instance=%hostname%/%plugin%",
                                "producer=%hostname%",
                                "stream=test_stream",
                                "output=/data/%hostname%.out"
                            ]
                        },
                    ],
                    "prdcrs" : [ # these producers will turn into `prdcr_add`
                        {
                            "name" : "agg-1",
                            "!extends" : "prdcr",
                            "port" : 20000,
                        },
                    ],
                    "config" : [ # additional config applied after prdcrs
                        "prdcr_subscribe regex=.* stream=test_stream",
                        "prdcr_start_regex regex=.*",
                    ],
                },
            ]
        },
    ],

    #"image": "ovis-centos-build:slurm",
    "cap_add": [ "SYS_PTRACE" ],
    "image": None,
    "ovis_prefix": "REPLACE_ME",
    "env" : {
        "LD_LIBRARY_PATH": "/data/tada/lib:/opt/ovis/lib:/opt/ovis/lib64",
        "LDMSD_PLUGIN_LIBPATH": "/data/tada/lib:/opt/ovis/lib/ovis-ldms:/opt/ovis/lib64/ovis-ldms",
    },
    "mounts": [ "{}:/tada-src:ro".format(os.path.realpath(sys.path[0])) ],
}

def rm(path):
    if os.path.exists(path):
        os.remove(path)

def prdcr_start_regex(agg, regex_str):
    if is_ldmsd_version_4(agg.ldmsd_version):
        txt = "prdcr_start_regex regex={}".format(regex_str)
    else:
        obj = { "request": "update",
                "id": 1,
                "schema": "prdcr",
                "enabled": True,
                "re": [regex_str]}
        txt = "json " + json.dumps(obj)
    return agg.config_ldmsd([txt])

def prdcr_stop_regex(agg, regex_str):
    if is_ldmsd_version_4(agg.ldmsd_version):
        txt = "prdcr_stop_regex regex={}".format(regex_str)
    else:
        obj = { "request": "update",
                "id": 1,
                "schema": "prdcr",
                "enabled": False,
                "re": [regex_str]}
        txt = "json " + json.dumps(obj)
    return agg.config_ldmsd([txt])

def prdcr_unsubscribe(node, regex, stream):
    """Tells ldmsd on `node` to prdcr_unsubscribe regex=`regex` stream=`stream`"""
    if is_ldmsd_version_4(node.ldmsd_version):
        txt = "prdcr_unsubscribe regex={} stream={}".format(regex, stream)
    else:
        raise NotImplementedError("prdcr_unsubscribe is not supported (yet) in v5")
    return node.config_ldmsd([txt])

def stream_client_dump(node):
    """Dump stream clients in ldmsd on node as a list of (stream_name, cb_fn, cb_ctxt) tuples"""
    if is_ldmsd_version_4(node.ldmsd_version):
        txt = "stream_client_dump"
    else:
        raise NotImplementedError("stream_client_dump is not supported (yet) in v5")
    rc, out = node.config_ldmsd([txt])
    obj = json.loads(out)
    lst = [ (s["name"], c["cb_fn"], c["ctxt"]) \
                    for s in obj["streams"] \
                    for c in s["clients"] ]
    return lst

def verify_msg(test, assert_no, msg, json_data, err_text):
    if msg["type"] == "json":
        if msg["obj"] != json_data:
            test.assert_test(assert_no, False, err_text)
            return False
    elif msg["type"] == "string":
        if msg["text"] != json.dumps(json_data):
            test.assert_test(assert_no, False, err_text)
            return False
    else:
        test.assert_test(assert_no, False,
                         "Unknown message type: {}".format(msg["type"]))
        return False
    return True

def start_publisher(cont, host, port, stream_type, fin):
    cmd = "ldmsd_stream_publish -h {host} -x {xprt} -p {port} -a munge " \
                               "-s {name} -t {type} -f {fin} 2>&1" \
          .format( host = host,
                       xprt = "sock",
                       port = port,
                       name = "test_stream",
                       type = stream_type,
                       fin = fin)
    rc, out = cont.exec_run(cmd)
    if rc:
        raise RuntimeError("Failed to start ldmsd_stream_publish. Error {}".format(rc))

if __name__ == "__main__":
    if sys.flags.interactive:
        exec(open(os.getenv("PYTHONSTARTUP", "/dev/null")).read())
    parser = argparse.ArgumentParser(description="ldmsd_stream_publish/subscribe FVT test")
    add_common_args(parser)
    args = parser.parse_args()
    process_args(args)

    clustername = args.clustername
    COMMIT_ID = args.commit_id

    spec["ovis_prefix"] = args.prefix
    spec["name"] = clustername
    spec["mounts"] += [ "{}:/data:rw".format(args.data_root) ]
    spec["mounts"] += args.mount
    if args.src:
        spec["mounts"] += [ "{0}:{0}:ro".format(args.src) ]
    spec["env"]["TADA_USER"] = args.user
    spec["env"]["TADA_ADDR"] = args.tada_addr
    spec["image"] = args.image

    # remove existing files
    rm(args.data_root + "/stream-sampler-1.out")
    rm(args.data_root + "/stream-sampler-2.out")
    rm(args.data_root + "/agg-2.out")

    # test = TADA.Test(args.cfg, args.prefix, args.data_root, args.tada_addr)
    test = TADA.Test(test_suite = "LDMSD",
                     test_type = "SVT",
                     test_name = "prdcr_subscribe_test",
                     test_desc = "LDMSD stream system verification test",
                     test_user = args.user,
                     commit_id = COMMIT_ID,
                     tada_addr = args.tada_addr)
    test.add_assertion(0, 'ldmsd_stream_publish of JSON data to stream-sampler-1 succeeds')
    test.add_assertion(1, 'ldmsd_stream_publish of STRING data to stream-sampler-1 succeeds')
    test.add_assertion(2, 'ldmsd_stream_publish to JSON data to stream-sampler-2 succeeds')
    test.add_assertion(3, 'ldmsd_stream_publish of STRING data to stream-sampler-2 succeeds')
    test.add_assertion(4, 'ldmsd_stream data check on agg-2')

    test.add_assertion(5, 'Stopping the producers succeeds')
    test.add_assertion(6, 'Restarting the producers succeeds')

    test.add_assertion(7, 'JSON stream data resumes after producer restart on stream-sampler-1')
    test.add_assertion(8, 'STRING stream data resumes after producer rerestart on stream-sampler-1')
    test.add_assertion(9, 'JSON stream data resumes after producer restart on stream-sampler-2')
    test.add_assertion(10, 'STRING stream data resumes after producer rerestart on stream-sampler-2')
    test.add_assertion(11, 'ldmsd_stream data resume check on agg-2')

    test.add_assertion(12, 'stream-sampler-1 is not running')
    test.add_assertion(13, 'stream-sampler-1 has restarted')
    test.add_assertion(14, 'JSON stream data resumes after stream-sampler-1 restart')
    test.add_assertion(15, 'STRING stream data resumes after stream-sampler-1 restart')
    test.add_assertion(16, 'ldmsd_stream data check on agg-2 after stream-sampler-1 restart')

    test.add_assertion(17, 'agg-1 unsubscribes stream-sampler-1')
    test.add_assertion(18, 'agg-1 receives data only from stream-sampler-2')

    test.add_assertion(19, 'stream-sampler-2 removes agg-1 stream client after disconnected')

    # Tell the TADA infrastructure that the test is starting
    test.start()

    # Create the containers required to ruyn the test
    cluster = LDMSDCluster.get(clustername, create = True, spec = spec)

    # Build libtest_stream_sampler before starting ldmsd
    cont = cluster.get_container("agg-1")
    # Cleanup old files
    rc, out = cont.exec_run("rm -f /data/*.out /data/*.json {}/*".format(TADA_LIB))
    rc, out = cont.exec_run("make -C {0}/C BUILDDIR={1}".format(TADA_SRC, TADA_LIB))
    if rc:
        raise RuntimeError("libtada build failed, output: {}".format(out))

    # Start all the LDMS Daemons configured in each container. NB: LDMSD can also be started
    # individually with start_daemon('hostname')
    cluster.start_daemons()

    # Give the daemons a few seconds to start
    time.sleep(5)

    # Create the test data
    data = { "gen" : 1,
             "schema" : "stream_test",
             "timestamp" : 1559242264,
             "data" : {
                 "id" : 12345,
                 "list" : [ 1, 2, 3, 4 ]
             }
         }
    text_data = json.dumps(data)
    data_file = '/data/Stream_Test-data.json'

    assert_no = 0
    for host in [ 'stream-sampler-1', 'stream-sampler-2' ]:
        cont = cluster.get_container(host)
        cont.write_file(data_file, text_data)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "json", data_file)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "string", data_file)

    # data verification
    samp1 = cluster.get_container("stream-sampler-1")
    samp2 = cluster.get_container("stream-sampler-2")
    agg1 = cluster.get_container("agg-1")
    agg2 = cluster.get_container("agg-2")

    samp1_out_txt = samp1.read_file("/data/stream-sampler-1.out")
    samp2_out_txt = samp2.read_file("/data/stream-sampler-2.out")
    agg2_out_txt = agg2.read_file("/data/agg-2.out")

    samp1_out = StringIO(samp1_out_txt)
    samp2_out = StringIO(samp2_out_txt)
    agg2_out = StringIO(agg2_out_txt)

    # Verify samp1
    for x in range(0, 2):
        msg = read_msg(samp1_out)
        if msg["type"] == "json":
            test.assert_test(0, msg["obj"] == data, "verify JSON data")
        elif msg["type"] == "string":
            test.assert_test(1, msg["text"] == text_data, "verify STRING data")
        else:
            raise RuntimeError("Bad message type")

    # Verify samp2
    for x in range(0, 2):
        msg = read_msg(samp2_out)
        if msg["type"] == "json":
            test.assert_test(2, msg["obj"] == data, "verify JSON data")
        elif msg["type"] == "string":
            test.assert_test(3, msg["text"] == text_data, "verify STRING data")
        else:
            raise RuntimeError("Bad message type")

    # Verify agg2
    text_count = 0
    json_count = 0
    _verify = True
    _verify_msg = "agg2 stream data verification"
    for x in range(0, 4):
        msg = read_msg(agg2_out)
        if msg["type"] == "string":
            text_count += 1
            _verify &= (msg["text"] == text_data)
        elif msg["type"] == "json":
            json_count += 1
            _verify &= (msg["obj"] == data)
        else:
            _verify = False
            _verify_msg = "Bad message type: {}".format(msg["type"])
    if _verify and (text_count != 2 or json_count != 2):
        _verify = False
        _verify_msg = "Message mismatch"
    test.assert_test(4, _verify, _verify_msg)

    agg_h = cluster.get_container('agg-1')
    rc, out = prdcr_stop_regex(agg_h, ".*")
    if is_ldmsd_version_4(agg_h.ldmsd_version):
        test.assert_test(5, (len(out) == 0), out)
    else:
        rsp = json.loads(out)
        test.assert_test(5, rsp["status"] == 0, rsp)

    rc, out = prdcr_start_regex(agg_h, ".*")
    if is_ldmsd_version_4(agg_h.ldmsd_version):
        test.assert_test(6, (len(out) == 0), out)
    else:
        rsp = json.loads(out)
        test.assert_test(6, rsp["status"] == 0, rsp)

    # give them time to reconnect before publishing new data
    time.sleep(5)

    # second set of data
    data = { "gen" : 2,
             "schema" : "stream_test",
             "timestamp" : 1559242274,
             "data" : {
                 "id" : 23456,
                 "list" : [ 1, 2, 3, 4, 5, 6 ]
             }
         }
    text_data = json.dumps(data)

    for host in [ 'stream-sampler-1', 'stream-sampler-2' ]:
        cont = cluster.get_container(host)
        cont.write_file(data_file, text_data)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "json", data_file)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "string", data_file)

    samp1_out_txt2 = samp1.read_file("/data/stream-sampler-1.out")
    samp2_out_txt2 = samp2.read_file("/data/stream-sampler-2.out")
    agg2_out_txt2 = agg2.read_file("/data/agg-2.out")

    samp1_out = StringIO(samp1_out_txt2)
    samp2_out = StringIO(samp2_out_txt2)
    agg2_out = StringIO(agg2_out_txt2)

    samp1_out.seek(len(samp1_out_txt))
    samp2_out.seek(len(samp2_out_txt))
    agg2_out.seek(len(agg2_out_txt))

    # Verify samp1
    for x in range(0, 2):
        msg = read_msg(samp1_out)
        if msg["type"] == "json":
            test.assert_test(7, msg["obj"] == data, "verify JSON data")
        elif msg["type"] == "string":
            test.assert_test(8, msg["text"] == text_data, "verify STRING data")
        else:
            raise RuntimeError("Bad message type")

    # Verify samp2
    for x in range(0, 2):
        msg = read_msg(samp2_out)
        if msg["type"] == "json":
            test.assert_test(9, msg["obj"] == data, "verify JSON data")
        elif msg["type"] == "string":
            test.assert_test(10, msg["text"] == text_data, "verify STRING data")
        else:
            raise RuntimeError("Bad message type")

    # Verify agg2
    text_count = 0
    json_count = 0
    _verify = True
    _verify_msg = "agg2 stream data verification"
    for x in range(0, 4):
        msg = read_msg(agg2_out)
        if msg["type"] == "string":
            text_count += 1
            _verify &= (msg["text"] == text_data)
        elif msg["type"] == "json":
            json_count += 1
            _verify &= (msg["obj"] == data)
        else:
            _verify = False
            _verify_msg = "Bad message type: {}".format(msg["type"])
    if _verify and (text_count != 2 or json_count != 2):
        _verify = False
        _verify_msg = "Message mismatch"
    test.assert_test(11, _verify, _verify_msg)

    cont = cluster.get_container('stream-sampler-1')

    cont.kill_ldmsd()
    time.sleep(1)
    running = cont.pgrepc('ldmsd')
    test.assert_test(12, (running == False), '(running == False)')

    cont.start_ldmsd()
    time.sleep(1)
    running = cont.pgrepc('ldmsd')
    test.assert_test(13, (running == True), '(running == True)')

    time.sleep(5) # allow some time for prdcr to reconnect

    data = { "gen" : 3,
             "schema" : "stream_test",
             "timestamp" : 1559250000,
             "data" : {
                 "id" : 78910,
                 "list" : [ 1  ]
             }
         }
    text_data = json.dumps(data)

    for host in [ 'stream-sampler-1' ]:
        cont = cluster.get_container(host)
        cont.write_file(data_file, text_data)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "json", data_file)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "string", data_file)

    # samp1 was reset
    samp1_out_txt3 = samp1.read_file("/data/stream-sampler-1.out")
    agg2_out_txt3 = agg2.read_file("/data/agg-2.out")

    samp1_out = StringIO(samp1_out_txt3)
    agg2_out = StringIO(agg2_out_txt3)

    agg2_out.seek(len(agg2_out_txt2))

    # Verify samp1
    for x in range(0, 2):
        msg = read_msg(samp1_out)
        if msg["type"] == "json":
            test.assert_test(14, msg["obj"] == data, "verify JSON data")
        elif msg["type"] == "string":
            test.assert_test(15, msg["text"] == text_data, "verify STRING data")
        else:
            raise RuntimeError("Bad message type")

    # Verify agg2
    text_count = 0
    json_count = 0
    for x in range(0, 2):
        msg = read_msg(agg2_out)
        if msg["type"] == "string":
            text_count += 1
            _verify &= (msg["text"] == text_data)
        elif msg["type"] == "json":
            json_count += 1
            _verify &= (msg["obj"] == data)
        else:
            _verify = False
            _verify_msg = "Bad message type: {}".format(msg["type"])
    if _verify and (text_count != 1 or json_count != 1):
        _verify = False
        _verify_msg = "Message mismatch"
    test.assert_test(16, _verify, _verify_msg)

    #test.add_assertion(17, 'agg-1 unsubscribes stream-sampler-1')
    rc, out = prdcr_unsubscribe(agg1, regex='stream-sampler-1', stream='test_stream')
    if is_ldmsd_version_4(agg_h.ldmsd_version):
        test.assert_test(17, (len(out) == 0), out)
    else:
        rsp = json.loads(out)
        test.assert_test(17, rsp["status"] == 0, rsp)

    #test.add_assertion(18, 'agg-1 receives data only from stream-sampler-2')

    samp1_out_txt_pre = samp1.read_file("/data/stream-sampler-1.out")
    samp2_out_txt_pre = samp2.read_file("/data/stream-sampler-2.out")
    agg2_out_txt_pre = agg2.read_file("/data/agg-2.out")

    data = {
            'stream-sampler-1': { "gen" : 4,
                 "schema" : "stream_test",
                 "timestamp" : 1559242274,
                 "data" : {
                     "id" : 23456,
                     "list" : [ 1, 1, 1, 1, 1, 1 ]
                 }
             },
            'stream-sampler-2': { "gen" : 4,
                 "schema" : "stream_test",
                 "timestamp" : 1559242274,
                 "data" : {
                     "id" : 23456,
                     "list" : [ 2, 2, 2, 2, 2, 2 ]
                 }
             },
         }

    for host in [ 'stream-sampler-1', 'stream-sampler-2' ]:
        _data = data[host]
        text_data = json.dumps(_data)
        cont = cluster.get_container(host)
        cont.write_file(data_file, text_data)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "json", data_file)
        start_publisher(cont, host, cont.ldmsd_spec["listen_port"], "string", data_file)

    samp1_out_txt_post = samp1.read_file("/data/stream-sampler-1.out")
    samp2_out_txt_post = samp2.read_file("/data/stream-sampler-2.out")
    agg2_out_txt_post = agg2.read_file("/data/agg-2.out")

    samp1_out = StringIO(samp1_out_txt_post)
    samp2_out = StringIO(samp2_out_txt_post)
    agg2_out = StringIO(agg2_out_txt_post)

    samp1_out.seek(len(samp1_out_txt_pre))
    samp2_out.seek(len(samp2_out_txt_pre))
    agg2_out.seek(len(agg2_out_txt_pre))

    while True: # this will break
        # samp1
        _data = data["stream-sampler-1"]
        _text_data = json.dumps(_data)
        # json and string
        msg = read_msg(samp1_out)
        if not verify_msg(test, 18, msg, _data, "stream-sampler-1 data verification failed"):
            break
        msg = read_msg(samp1_out)
        if not verify_msg(test, 18, msg, _data, "stream-sampler-1 data verification failed"):
            break
        # samp2
        _data = data["stream-sampler-2"]
        _text_data = json.dumps(_data)
        # json and string
        msg = read_msg(samp2_out)
        if not verify_msg(test, 18, msg, _data, "stream-sampler-2 data verification failed"):
            break
        msg = read_msg(samp2_out)
        if not verify_msg(test, 18, msg, _data, "stream-sampler-2 data verification failed"):
            break
        # agg-2 - expects only 2 messages from samp2
        _data = data["stream-sampler-2"]
        _text_data = json.dumps(_data)
        # json and string
        msg = read_msg(agg2_out)
        if not verify_msg(test, 18, msg, _data, "agg-2 data verification failed"):
            break
        msg = read_msg(agg2_out)
        if not verify_msg(test, 18, msg, _data, "agg-2 data verification failed"):
            break
        if agg2_out.tell() != len(agg2_out_txt_post):
            test.assert_test(18, False, "agg-2 has extra stream data")
            break
        test.assert_test(18, True, "data verified")
        break

    #test.add_assertion(19, 'stream-sampler-2 removes agg-1 stream client after disconnected')
    # Get client dump from stream-sampler-2 before killing agg-1
    while True: # this will break
        before = stream_client_dump(samp2)
        # Kill agg-1
        agg1.kill_ldmsd()
        time.sleep(5)
        # Get client dump from stream-sampler-2
        after = stream_client_dump(samp2)
        before = set(before)
        after = set(after)
        if not (after < before):
            diff = after - before
            if diff:
                test.assert_test(19, False, "Unexpected streams/clients: {}".format(diff))
            else:
                test.assert_test(19, False, "streams/clients not removed: {}".format(after))
            break
        diff = set(before) - set(after)
        if len(diff) != 1:
            test.assert_test(19, False, "Too many terminated clients: {}".format(diff))
            break
        stream_name, cb_fn, ctxt = diff.pop()
        if stream_name != "test_stream":
            test.assert_test(19, False, "Unexpected stream name: {}".format(stream_name))
            break
        if not re.match(r'\S*ldmsd\(', cb_fn):
            test.assert_test(19, False, "Unexpected cb_fn: {}".format(cb_fn))
            break
        test.assert_test(19, True, "verified")
        break

    test.finish()
    # cleanup data
    flist = [ "agg-2.out", "stream-sampler-1.out", "stream-sampler-2.out",
              "Stream_Test-data.json", "tada/" ]
    flist = [ "/data/{}".format(x) for x in flist ]
    rm = "rm -rf " + ( " ".join(flist) )
    agg2.exec_run(rm)
    cluster.remove()
